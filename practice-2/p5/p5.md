# Practice Problems 5 Solutions

## 1. One Answer

Imagine you are building a machine learning model to predict the stopping distance of cars based on their speed.

You obtain a large dataset where each data point is a pair of observed speeds and stopping distances, and you decide to use a simple linear regression model to predict stopping distances from speed.

However, in reality, the stopping distance increases quadratically with speed.
As a result, your model consistently underestimates the stopping distance at higher speeds.

Compared to using a model that can model a quadratic relationship between stopping distance and speed, would your model have high or low bias?

a. High bias

b. Low bias

## 2. One Answer

Follow the same car scenario as the above question. Compared to using a model that can model a quadratic relationship between stopping distance and speed, would your model have high or low variance?

a. High variance

b. Low variance

## 3. One Answer

Follow the same car scenario as the above question. In reality, stopping distance is also affected by weather conditions, which your our model does not capture.
Which of these components of overall model error captures the error from not including weather conditions as a feature?

a. Bias

b. Variance

c. Irreducible error

## 4. Select All That Apply

Which of the following will generally help to reduce model variance?

a. Increasing the size of the training data.

b. Increasing the size of the validation data.

c. Increasing the number of model parameters.

d. Increasing the amount of regularization.

## 5. One Answer

For machine learning models and datasets in general, as the number of training data points grows, the prediction error of the model on unseen data (data not found in the training set) approaches 0.

a. True

b. False

## 6. Select All That Apply

Which of the following statements about (binary) logistic regression is true?
Recall that the sigmoid function is defined as $\sigma(x)=\frac{1}{1+e^{-x}}$ for $x\in\mathbb{R}.$

a. For any finite input $x\in\mathbb{R}$, $\sigma(x)$ is strictly greater than 0 and strictly less than 1. Thus, a binary logistic regression model with finite input and weights can never output a probability of exactly 0 or 1, and can never achieve a training loss of exactly 0.

b. The first derivative of $\sigma$ is monotonically increasing.

c. There exists a constant value $c\in\mathbb{R}$ such that $\sigma$ is convex when restricted to $x<c$ and concave when restricted to $x\ge c$

d. For binary logistic regression, if the probability of the positive class is $\sigma(x)$ then the probability of the negative class is $\sigma(-x)$

## 7. Select All That Apply

Consider performing Lasso regression by finding parameters $w\in\mathbb{R}^{d}$ that minimize

$$f(w)=\sum_{i=1}^{n}(y^{(i)}-x^{(i)\top}w)^{2}+\lambda||w||_{1}.$$ 

Which of the following statements are true?

a. Increasing $\lambda$ will generally reduce the $L_{1}$ norm of the parameters $w$.

b. Consider two models $w_{1}$, $w_{2}\in\mathbb{R}^{d}.$ Assume $w_{1}$ is more sparse, i.e., $w_{1}$
has strictly more zero coefficients than $w_{2}$. Then $||w_{1}||_{1}<||w_{2}||_{1}$

c. Increasing $\lambda$ generally increases model bias.

d. Increasing $\lambda$ generally increases model variance.

## 8. Select All That Apply

Which of the following statements about ridge regression are true?

a. When there are correlated features, ridge regression typically sets the weights of all but one of the correlated features to 0.

b. Compared to unregularized linear regression, the additional computational cost of ridge regression scales with respect to the number of data points in the dataset.

c. Ridge regression reduces variance at the expense of increasing bias.

d. Using ridge and lasso regularization together (e.g., minimizing a training objective of the form $$f(w)=\sum_{i=1}^{n}(y^{(i)}-x^{(i)\top}w)^{2}+\lambda_{1}||w||_{1}+\lambda_{2}||w||_{2}^{2})$$ makes the training loss no longer convex.

## 9. Select All That Apply

Consider minimizing a function $f(x):\mathbb{R}\rightarrow\mathbb{R}$.
Recall the following definitions:
- $x\in\mathbb{R}$ is a global minimum for $f$ if $f(x^{\prime})\ge f(x)$ for all $x^{\prime}\in\mathbb{R}$
- $x\in\mathbb{R}$ is a local minimum for $f$ if there exists $\epsilon>0$ such that $f(x^{\prime})\ge f(x)$ for all $x^{\prime}\in\mathbb{R}$ within $\epsilon$ distance of $x$, that is, $|x^{\prime}-x|<\epsilon.$

Which of the following statements are true?

a. All linear functions $f(x)=ax+b$ for some $a, b\in\mathbb{R}$ are both convex and concave.

b. If $f$ is convex, then it can have at most one global minimum. (That is, if $u, v\in\mathbb{R}$
are both global minima for $f$, then that implies $u=v$.)

c. If $f$ is convex, then all local minima are global minima.

d. If $f$ is convex and bounded below (i.e., there exists $c\in\mathbb{R}$ such that $f(x)\ge c$ for all
$x\in\mathbb{R}$) then it must have at least one global minimum.

e. If $f$ is concave, then it must have no global minima.

## 10. One Answer

Let's say we want to standardize our data (i.e., normalizing the data to have zero mean and unit variance in each dimension) for the purposes of training and evaluating a ML model.
Which of the following would be most appropriate?

a. Split the dataset into the train/val/test splits, standardize the data separately for each split using the mean and variance statistics of that split.

b. Split the dataset into the train/val/test splits, standardize the data for the training set, and use the mean and variance statistics of the training data to standardize the validation and test sets.

c. Split the dataset into the train/val/test splits, standardize the training and validation sets separately using the mean and variance statistics of each split, then use the mean and variance statistics of the validation split to normalize the test set.

d. Standardize the entire dataset (i.e., all splits combined) using the combined mean and variance statistics.
Then, split the standardized data into train/val/test sets.

## 11. Select All That Apply

Which of the following statements about gradient descent are true?
Recall that the gradient descent algorithm updates the weight parameter $w$ at iteration $t$ as follows: $$w_{t+1}=w_{t}-\eta\nabla_{w}l(w)|_{w=w_{t}}$$ (with $\eta$ being the step size).
For this question, we say that gradient descent has converged by iteration $T$ if there is some iteration $t<T$ such that $||\nabla_{w}l(w_{t})||_{2}^{2}\le\epsilon$ for some fixed $\epsilon>0$.

a. The gradient $\nabla_{w}l(w)$ points in the direction that maximizes the training loss.

b. Assume $l(w)$ is convex. Then if gradient descent converges by iteration $T$ for some
fixed $\epsilon>0$ and some step size $\eta$, it will converge in at most $T$ iterations if we increase the step size $\eta$.

c. Assume $l(w)$ is convex. Then if gradient descent converges by iteration $T$ for some fixed $\epsilon>0$ and some step size $\eta$, it will also eventually converge for all smaller step sizes $0<\eta^{\prime}<\eta$ given enough iterations.

## 12.

Describe one advantage of mini-batch stochastic gradient descent over full-batch gradient descent.

## 13.

Describe one advantage of mini-batch stochastic gradient descent $(1<B<n)$ over stochastic gradient descent with batch size $B=1$ (e.g., updating the parameters at each iteration based only on one randomly sampled training point).

## 14. One Answer

In a machine learning course, the distribution of final exam scores is approximately normal.
However, an administrative error provided some students with prior access to practice materials closely resembling the exam, resulting in significant score increases for these students.
Considering only the scores and without labeled information about who had access to the materials, what type of model would be most appropriate to estimate the likelihood that a given student had access to the practice materials?

## 15. Select All That Apply

Assume we are given a fixed dataset $D=\{x^{(1)},x^{(2)},...,x^{(n)}\}$ drawn i.i.d. (independently and identically distributed) from an underlying distribution $P(x)$.
We use the bootstrap to draw bootstrap samples $\tilde{D}=\{\tilde{x}^{(1)},\tilde{x}^{(2)},...\}$ from a bootstrap distribution $Q(x)$.
Which of the following statements are true?

a. The bootstrap samples in $\tilde{D}$ are drawn by sampling with replacement from D.

b. The bootstrap samples in $\tilde{D}$ are drawn by sampling without replacement from D.

c. The distribution of bootstrap samples in $\tilde{D}$ is always identical to the underlying data distribution P.

d. The bootstrap samples in $\tilde{D}$ are independently and identically distributed.

## 16.

You are given a dataset with four data points $x^{(1)}, x^{(2)}, x^{(3)}, x^{(4)}\in\mathbb{R}$. The coordinates of these data points are:
- $x^{(1)}=0$
- $x^{(2)}=1$
- $x^{(3)}=5$
- $x^{(4)}=9$.

You run k-means on this dataset with $k=3$ centroids, initialized at the first 3 data points: 0, 1, and 5. After k-means converges, what will be the new coordinates of these centroids?
Give your answer as a sequence of 3 numbers in ascending order (e.g., "0, 1, 5").

## 17. Select All That Apply

Which of the following statements are true about k-means?

a. The output of k-means can change depending on the initial centroid positions.

b. Assuming that the number of data points is divisible by k, k-means with k clusters always outputs clusters of equal sizes.

c. If run for long enough, k-means will always find the globally optimal solution (as measured by the average L2 distance between each point and its assigned cluster centroid).

d. K-means will not converge unless all clusters in the underlying data distribution have equal, spherical variance.

## 18.

Should we initialize all the weights of a neural network to be the same small constant value (e.g., 0.001)?
Why or why not?

## 19. Select All That Apply

In a neural network, the number of layers is an important hyperparameter.
Which of these statements are true about adding layers to a neural network (keeping all other aspects of the model and training process the same)?

a. Hyperparameters are independent, i.e., adding more layers will not affect the optimal choice of step size for gradient descent or the amount of regularization needed.

b. We cannot use cross-validation to select hyperparameters that directly affect model architecture, such as the number of layers.

c. Adding more layers generally decreases the training loss.

d. Adding more layers generally increases the ability of the model to overfit the data.

## 20. Select All That Apply

Which of the following are advantages of Gaussian Mixture Models (GMMs) over K-means for a clustering application?

a. GMMs are better suited if clusters have varying sizes and/or shapes.

b. GMMs are better equipped to model overlapping clusters.

c. GMMs are better suited to reason probabilistically about the data and the clusters.

d. On a given dataset, a single iteration of the EM algorithm for fitting a GMM requires less computation than a single iteration of Lloyd's Algorithm for fitting K-means.

## 21. One Answer

Kernel methods calculate the inner products of features in a transformed feature space, without explicitly computing the transformed features.

a. True

b. False

## 22. One Answer

Consider a fully connected neural network (MLP) with an input layer, a hidden layer, and an output layer.
The input layer has n units, the hidden layer has h units, and the output layer has m units.
Assume there are no bias units/terms. Which of the following statements about the number of trainable parameters is true?

a. The total number of trainable parameters is $n \cdot h \cdot m$.

b. The total number of trainable parameters is $n \cdot h + h \cdot m$.

c. The total number of trainable parameters is $(n + 1) \cdot h + (h + 1) \cdot m$.

d. The total number of trainable parameters is $n + h + m$.

## 23. Select All That Apply

Consider a matrix $A \in \mathbb{R}^{m \times n}$ with singular value decomposition $A = USV^\top$, where $S$ is an $r \times r$ diagonal matrix and $r = \operatorname{rank}(A) \leq \min(m, n)$.

Which of the following statements are correct?

a. The columns of $U$ are the eigenvectors of $A^\top A$.

b. The columns of $U$ are the eigenvectors of $A A^\top$.

c. The columns of $V$ are the eigenvectors of $A^\top A$.

d. The columns of $V$ are the eigenvectors of $A A^\top$.

e. The singular values in $S$ are the square roots of the nonzero eigenvalues of $A A^\top$.

f. The singular values in $S$ are the square roots of the nonzero eigenvalues of $A^\top A$.

## 24.

Consider a dataset $X \in \mathbb{R}^{n \times p}$ with $n$ observations and $p$ features, and with corresponding covariance matrix $\Sigma$.

Let $\lambda_{1} \geq \lambda_{2} \geq ... \geq \lambda_{p}$ be the eigenvalues of $\Sigma$ in descending order.

Express the total variance explained by the first $k$ principal components (obtained by performing Principal Component Analysis (PCA) on $X$) as a fraction of the total variance in the original data.

## 25.

Consider a dataset $X \in \mathbb{R}^{n \times 2}$ with $n$ observations and 2 features.
Suppose $\Sigma$ is the covariance matrix of the dataset:

$$
\Sigma = \begin{pmatrix} 3 & \sqrt{3} \\ \sqrt{3} & 5 \end{pmatrix}
$$

This covariance matrix has the following unit-norm eigenvectors $u$ and $v$:

$u = \frac{1}{2}\begin{pmatrix} -\sqrt{3} \\ 1 \end{pmatrix}$, $v = \frac{1}{2}\begin{pmatrix} 1 \\ \sqrt{3} \end{pmatrix}$

Write the second principal component as a unit-length vector in vector form (i.e., $[a, b]$).

## 26. Select All That Apply

You are applying PCA to a training dataset of $n = 1024$ grayscale images that are each $16 \times 16$ pixels ($256$ pixels per image).
Consider reshaping each image into a vector $x_i \in \mathbb{R}^{256}$ and then composing a data matrix $X \in \mathbb{R}^{1024 \times 256}$, where the $i$th row is $x_i^\top$.
Let $\hat{x}_{i,k} \in \mathbb{R}^{256}$ be the PCA reconstruction of image $x_i$ using the top $k$ principal component directions in the data.
Let $R(k)$ be the average reconstruction error on the training data using $k$ principal components, $R(k) = \frac{1}{n} \sum_{i=1}^{n} ||x_i - \hat{x}_{i,k}||^2_2$.
Which of the following statements are true?

a. $R(k)$ is monotonically decreasing as $k$ increases, up to $k = 1024$. That is, if $0 < k_1 < k_2 \leq 1024$, then $R(k_1) > R(k_2)$.

b. If $k < \operatorname{rank}(X)$, then $R(k) > 0$.

c. If $k \geq \operatorname{rank}(X)$, then $R(k) = 0$.

d. For $k \geq 1$, let $\delta(k) = R(k-1) - R(k)$ be the decrease in reconstruction error by going from $k-1$ to $k$ principal components.
(When $k = 0$, define the reconstruction of $x_i$ to simply be the mean image $\bar{x}$.) Then, $\delta(k)$ is monotonically non-increasing as $k$ increases.

## 27. Select All That Apply

Which of the following is/are true about the $k$-Nearest Neighbors (k-NN) algorithm?

a. Testing time (i.e., the amount of time it takes to produce an output for a new test point) increases with the number of training samples.

b. The number of hyperparameters increases with the number of training samples.

c. $k$-NN can learn non-linear decision boundaries.

d. $k$-NN clusters unlabeled samples in a $k$-dimensional space based on their similarity.

## 28. Select All That Apply

Which of the following statements about random forests and decision trees are true?

a. Random forests are generally easier for humans to interpret than individual decision trees.

b. Random forests reduce variance (compared to individual decision trees) by aggregating predictions over multiple decision trees.

c. When constructing the individual trees in the random forest, we want their predictions to be as correlated with each other as possible.

d. Random forests can give a notion of confidence estimates by examining the distribution of outputs that each individual tree in the random forest produces.

## 29. Select All That Apply

Which of the following is a correct statement about (mini-batch) Stochastic Gradient Descent (SGD)?

a. The variance of the gradient estimates in SGD decreases as the batch size increases.

b. Running SGD with batch size 1 for n iterations is generally slower than running full batch gradient descent with batch size n for 1 iteration, because the gradients for each training point in SGD have to be computed sequentially, whereas the gradients in full-batch gradient descent can be computed in parallel.

c. SGD is faster than full-batch gradient descent because it only updates a subset of model parameters with each step.

d. SGD provides an unbiased estimate of the true (full-batch) gradient of the training loss.

## 30. One Answer

The probability density function for a gamma distribution with parameters $\theta > 0$, $k > 0$ is
$f(x; \theta, k) = \frac{1}{\Gamma(k)\theta^k}x^{k-1}e^{- \frac{x}{\theta}}$,
where
$\Gamma(x) = (x − 1)!$

Say we have a dataset D of n data points, $\{x^{(1)}, x^{(2)}, \ldots, x^{(n)}\}$, where each $x \in \mathbb{R}$.

Assume that k is given to us and fixed.

We would like to use D to find the maximum likelihood estimator for $\theta$.
What is the maximum likelihood estimator for $\theta$ in terms of k, n, and $x^{(1)}, x^{(2)}, \ldots, x^{(n)}$?

Hint: The argmax of the logarithm of a function is the same as the argmax of the function.

a. $\frac{1}{kn}\sum_{i=1}^{n} x^{(i)}$

b. $\frac{n(k-1)!}{\sum_{i=1}^{n} x^{(i)}e^{- \frac{x^{(i)}}{k}}}$

c. $\ln(\frac{1}{n}\sum_{i=1}^{n} x^{(i)}) − n(k − 1)!$

d. $\ln(k)−\frac{(k-1)!}{k}$

## 31. One Answer

Many ML algorithms, like the k-nearest neighbors (k-NN) algorithm, relies on distances between points.

In high-dimensional spaces, distances can behave counterintuitively. This question illustrates one such example.

Consider two d-dimensional hypercubes S and T centered around the origin.
S has side length 2, while T is contained within S and has side length 1:
$S = \{x \in \mathbb{R}^d: ||x||_\infty \le 1\}$
$T = \{x \in \mathbb{R}^d: ||x||_\infty \le \frac{1}{2}\}$.

Alternatively, we can write $S = [-1, 1]^d$, and $T = [-\frac{1}{2},\frac{1}{2}]^d$.

Let P be the uniform distribution of points in S. What is the probability of drawing a point x ∼ P such that x ∈ T, that is, x is contained within T?

Give your answer in terms of d.

## 32. Select All That Apply

Consider the following dataset of four points in $\mathbb{R}^2$:

$x^{(1)} = (0, 0)$ $y^{(1)} = −1$

$x^{(2)} = (0, 1)$ $y^{(2)} = +1$

$x^{(3)} = (1, 0)$ $y^{(3)} = +1$

$x^{(4)} = (1, 1)$ $y^{(4)} = −1$.

This is also known as a XOR problem because the labels y are the result of applying the XOR operation to the two components of x.

For a given data point $x \in \mathbb{R}^2$, denote its first dimension as $x_1$ and its second dimension as $x_2$.

For example, $x^{(2)}_1 = 0$ and $x^{(2)}_2 = 1$. Which of the following statements are true?

a. There exists a linear model $w \in \mathbb{R}^3$, which predicts +1 if
$w^\top \begin{bmatrix} x_1 \\ x_2 \\ 1 \end{bmatrix} \ge 0$
and −1 otherwise, that achieves 100% accuracy on this dataset.

b. There exists a linear model $w \in \mathbb{R}^6$, which predicts +1 if
$w^\top \begin{bmatrix} x_1 \\ x_2 \\ x_1^2 \\ x_2^2 \\ x_1x_2 \\ 1 \end{bmatrix} \ge 0$
and −1 otherwise, that achieves 100% accuracy on this dataset.

c. Define a polynomial feature expansion $\phi(x)$ as any function $\phi(x) : \mathbb{R}^2 \to \mathbb{R}^d$ that can be written as
$\begin{bmatrix} x_1^{a_1} x_2^{b_1} \\ x_1^{a_2} x_2^{b_2} \\ \vdots \\ x_1^{a_d} x_2^{b_d} \end{bmatrix}$
for some integer d > 0 and integer vectors a, b $\in \mathbb{Z}^d$.

Then there does not exist any polynomial feature expansion $\phi(x)$ such that a linear model w which predicts +1 if $w^\top\phi(x) \ge 0$, and −1 otherwise, achieves 100% accuracy on this dataset.

## 33. One Answer

Consider the following transfer learning setting.

We have a large neural network $\phi : \mathbb{R}^d \to \mathbb{R}^p$ pretrained on ImageNet, and we would like to use this to learn a classifier for our own binary classification task for medical images.

We decide to freeze the neural network $\phi$ and train a logistic regression classifier on top.

Formally, we are given $n$ data points from our own medical imaging task $\{(x^{(1)}, y^{(1)}),(x^{(2)}, y^{(2)}), \ldots, (x^{(n)}, y^{(n)})\}$, where $x^{(i)} \in \mathbb{R}^d$, $y^{(i)} \in \{-1, +1\}$.

We train a classifier $\hat{w} \in \mathbb{R}^p$:

$$\hat{w}= \operatorname{argmin}_{w \in \mathbb{R}^p} \sum_{i=1}^{n} \log \left( 1 + \exp \left( -y^{(i)}w^\top\phi(x^{(i)}) \right) \right).$$

Which of the following statements is true?

a. Learning $\hat{w}$ in this way is a convex optimization problem regardless of how complex $\phi$ is.

b. Learning $\hat{w}$ in this way is a convex optimization problem if and only if $\phi$ is a convex function in each dimension.
(Let $\phi = [\phi_1; \phi_2; \ldots ; \phi_p]$; then we say $\phi$ is convex in each dimension if each of $\phi_1, \phi_2, \ldots, \phi_p$ is a convex function).

c. Learning $\hat{w}$ in this way is a convex optimization problem if and only if $\phi$ is a linear function.

d. Learning $\hat{w}$ in this way is a convex optimization problem if and only if $\phi$ is the identity function and $p = d$.

## 34.

Recall that influence functions are used to approximate the effect of leaving out one training point, without actually retraining the model.

Assume that we have a twice-differentiable, strongly convex loss function $\ell(x, y; w)$, and as usual, we train a model $\hat{w}$ to minimize the average training loss:

$$\hat{w}= \operatorname{argmin}_{w} \frac{1}{n} \sum_{i=1}^{n} \ell_i(w),$$

where $\{(x^{(1)}, y^{(1)}),(x^{(2)}, y^{(2)}), \ldots, (x^{(n)}, y^{(n)})\}$ is our training set, and for notational convenience we define $\ell_i(w) = \ell(x^{(i)}, y^{(i)}; w)$.

Let $\Delta_{-i}$ be the change in the parameters $w$ after we remove training point $(x^{(i)}, y^{(i)})$ and retrain the model.

The influence function approximation tells us that

$$\Delta_{-i} = \frac{1}{n} H(\hat{w})^{-1} \nabla_w \ell_i(w) \Big|_{w=\hat{w}}$$

where the Hessian matrix $H(\hat{w})$ is defined as

$$H(\hat{w}) = \frac{1}{n} \sum_{i=1}^{n} \nabla_w^2 \ell_i(w) \Big|_{w=\hat{w}}$$

Consider the following linear regression model $f_w(x) = w^\top x$, where $x, w \in \mathbb{R}^d$.
We train with unregularized least squares regression to obtain $\hat{w}$.

What is $\Delta_{-i}$ for this model, in terms of $\hat{w}$ and the training data points?

Note: The symbols $\ell$ and $H$ should not appear in your answer. Replace them by working out the appropriate loss. 