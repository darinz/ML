{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c261c6-6cec-4cb5-9ac4-a554dc3e8d6a",
   "metadata": {},
   "source": [
    "# Practice 9 Solutions\n",
    "\n",
    "**Problem 1. One Answer**\n",
    "\n",
    "In a popular gacha game, the probability of pulling an SSR character on a single pull is 0.6% (P = 0.006). Assume that each pull is independent and follows a Bernoulli distribution. In such games, players often perform a 10-pull, which means making 10 pulls. Each of these 10 pulls is still independent, meaning the probability of getting an SSR in each pull remains 0.006. If you perform a 10-pull, what is the probability of pulling exactly 2 SSRs? You do not need to know what gacha game is to solve this problem.\n",
    "\n",
    "*   (a) 0\n",
    "*   (b) $1 - (1 - P)^{10} = 5.84\\%$\n",
    "*   (c) $(1 - P)^9 \\times P \\times 10 = 5.68\\%$\n",
    "*   (d) $(1 - P)^8 \\times P^2 \\times (10 \\times 9 / 2) = 0.15\\%$\n",
    "\n",
    "**Correct answers:** (d)\n",
    "\n",
    "**Explanation:** We model each pull as a Bernoulli trial, where the probability of success (pulling an SSR) is P = 0.006. Since a 10-pull consists of 10 independent trials, the number of SSRs obtained follows a Binomial distribution:\n",
    "\n",
    "$X \\sim \\text{Binomial}(n = 10, p = 0.006)$\n",
    "\n",
    "We want to find the probability of pulling exactly 2 SSRs, which is given by the binomial probability mass function (PMF):\n",
    "\n",
    "$P(X = 2) = \\binom{10}{2} P^2 (1 - P)^8$\n",
    "\n",
    "Computing the combination: $\\binom{10}{2} = \\frac{10!}{2! \\times (10 - 2)!} = \\frac{10 \\times 9}{2} = 45$\n",
    "\n",
    "Thus, the probability is: $P(X = 2) = (1 - P)^8 \\times P^2 \\times 45 = 0.15\\%$\n",
    "\n",
    "Therefore, the correct answer is D.\n",
    "\n",
    "**Why other options are incorrect:**\n",
    "\n",
    "**A: 0** - This option would be correct if it were impossible to pull an SSR. However, since the probability of obtaining an SSR is nonzero, this option is incorrect.\n",
    "\n",
    "**B: $1 - (1 - P)^{10} = 5.84\\%$** - This formula calculates the probability of pulling at least 1 SSR, computed as: $P(\\text{at least 1 SSR}) = 1 - P(0 \\text{ SSRs}) = 1 - (1 - P)^{10}$. This probability includes cases where the player gets 1, 2, 3, ..., or even 10 SSRs.\n",
    "\n",
    "**C: $(1 - P)^9 \\times P \\times 10 = 5.68\\%$** - This formula calculates the probability of pulling exactly 1 SSR, given by: $P(X = 1) = \\binom{10}{1} P^1(1 - P)^9 = 10 \\times P \\times (1 - P)^9$. Hence, the correct answer remains D.\n",
    "\n",
    "**Problem 2. Select All That Apply**\n",
    "\n",
    "Below are several statements about Gradient Descent (GD) and Stochastic Gradient Descent (SGD). Which of the following are correct?\n",
    "\n",
    "*   (a) For GD, each step aims to move along the gradient descent direction at the current point to reduce the value of the objective function.\n",
    "*   (b) In SGD, each step computes an estimated gradient based on a single sample, introducing randomness, which may not guarantee that the objective function decreases in every step.\n",
    "*   (c) Suppose you have model $w_t$ at the $t$-th iteration of SGD. The expectation of the direction of the model update for SGD at step $t$ is different from the negative direction of the gradient $-\\nabla_w f(w)|_{w=w_t}$.\n",
    "*   (d) GD requires the full gradient information of the objective function, while SGD only needs the gradient information on a single sample at each step.\n",
    "\n",
    "**Correct answers:** (a), (b), (d)\n",
    "\n",
    "**Explanation:** The correct answers are (A), (B), and (D). Below is an explanation of each option.\n",
    "\n",
    "**(A) Correct:** In Gradient Descent (GD), each step moves in the direction of the negative gradient of the objective function at the current point. This ensures that the function value decreases (assuming an appropriate step size). Mathematically, the update rule for GD is:\n",
    "\n",
    "$w_{t+1} = w_t - \\eta \\nabla_w f(w_t)$\n",
    "\n",
    "where $\\eta$ is the learning rate, and $\\nabla_w f(w_t)$ is the gradient of the objective function over the entire dataset at iteration $t$. This step guarantees movement in the direction that minimizes the objective function.\n",
    "\n",
    "**(B) Correct:** In Stochastic Gradient Descent (SGD), instead of computing the exact gradient using the full dataset, an estimated gradient is computed based on a single sample (or a mini-batch). This introduces randomness in the updates, meaning that the objective function might not necessarily decrease in every step. The update rule for SGD can be rewritten as:\n",
    "\n",
    "$w_{t+1} = w_t - \\eta(\\nabla_w f(w_t) + \\xi_t)$\n",
    "\n",
    "where $\\nabla_w f(w_t)$ is the true full-batch gradient, and $\\xi_t$ is a noise term introduced due to the stochastic nature of SGD, representing the deviation from the full gradient when using only one sample. This noise term makes each individual update potentially non-optimal, but in expectation, the updates still align with the true gradient direction over multiple iterations.\n",
    "\n",
    "**(C) Incorrect:** The expectation of the SGD update direction is equal to the negative full gradient:\n",
    "\n",
    "$E[\\nabla_w f(w_t) + \\xi_t] = \\nabla_w f(w_t)$\n",
    "\n",
    "Since SGD approximates the full gradient using randomly sampled data points, its update direction is an unbiased estimate of the true gradient. That is, while each step introduces noise, on average, the update follows the same direction as GD. Therefore, the claim that the expectation is different from $-\\nabla_w f(w_t)$ is false.\n",
    "\n",
    "**(D) Correct:** GD requires the full gradient of the objective function, meaning it computes $\\nabla_w f(w)$ over the entire dataset at each step. In contrast, SGD only uses the gradient of a single sample (or a mini-batch), significantly reducing the computational cost per step, especially in large-scale datasets.\n",
    "\n",
    "Therefore, the correct answers are (A), (B), and (D).\n",
    "\n",
    "**Problem 3.**\n",
    "\n",
    "In a gacha game, the probability of obtaining an SSR character per pull is $p$, but $p$ is unknown. To estimate $p$, Bob performed 100 pulls and obtained SSRs $k = 3$ times (i.e., 3 successes). Assume that each pull is independent and follows a Bernoulli distribution.\n",
    "\n",
    "What is the likelihood of this scenario occurring?\n",
    "\n",
    "Likelihood function: $L(p) = \\frac{100 \\times 99 \\times 98}{6} p^3 (1-p)^{97}$\n",
    "\n",
    "What is the Maximum Likelihood Estimate (MLE) of $p$ as a fractional number?\n",
    "\n",
    "MLE: $\\hat{p} = \\frac{3}{100}$\n",
    "\n",
    "**Explanation:** Since each pull is independent and follows a Bernoulli distribution, the total number of SSRs obtained follows a Binomial distribution:\n",
    "\n",
    "$X \\sim \\text{Binomial}(n = 100, p)$\n",
    "\n",
    "The likelihood function is given by the binomial probability mass function:\n",
    "\n",
    "$L(p) = \\binom{100}{3} p^3 (1-p)^{97} = \\frac{100 \\times 99 \\times 98}{6} p^3 (1-p)^{97}$\n",
    "\n",
    "To find the MLE $\\hat{p}$, we maximize $\\ln L(p)$:\n",
    "\n",
    "$\\ln L(p) = \\text{constant} + 3 \\ln p + 97 \\ln(1-p)$\n",
    "\n",
    "Taking the derivative and setting it to zero:\n",
    "\n",
    "$\\frac{3}{p} - \\frac{97}{1-p} = 0$\n",
    "\n",
    "Solving for p:\n",
    "\n",
    "$\\hat{p} = \\frac{3}{100}$\n",
    "\n",
    "**Problem 4. One Answer**\n",
    "\n",
    "Suppose you train a linear regression model (without doing feature expansion), i.e., $f_w(x) = wx + b$, to approximate the cubic function $g(x) = 2x^3 + 7x^2 + 4x + 3$. What's the most likely outcome?\n",
    "\n",
    "*   (a) The model will have low bias and low variance\n",
    "*   (b) The model will have low bias and high variance\n",
    "*   (c) The model will have high bias and low variance\n",
    "*   (d) The model will have high bias and high variance\n",
    "\n",
    "**Correct answers:** (c)\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "**This question tests understanding of bias-variance tradeoff** in model complexity.\n",
    "\n",
    "**Why (c) is correct:**\n",
    "\n",
    "**Linear model approximating cubic function creates high bias, low variance:**\n",
    "\n",
    "**1. Model complexity analysis:**\n",
    "- **Linear model:** $f_w(x) = wx + b$ (degree 1)\n",
    "- **Target function:** $g(x) = 2x^3 + 7x^2 + 4x + 3$ (degree 3)\n",
    "- **Model is too simple** for the target function\n",
    "- **Cannot capture** cubic relationships\n",
    "\n",
    "**2. High bias (underfitting):**\n",
    "- **Systematic error** due to model simplicity\n",
    "- **Cannot represent** the true underlying function\n",
    "- **Consistent deviation** from target values\n",
    "- **Model assumptions** are wrong\n",
    "\n",
    "**3. Low variance:**\n",
    "- **Simple model** has few parameters\n",
    "- **Less sensitive** to training data variations\n",
    "- **Stable predictions** across different datasets\n",
    "- **Consistent behavior** regardless of data\n",
    "\n",
    "**4. Why other options are incorrect:**\n",
    "\n",
    "**Option (a): Low bias, low variance**\n",
    "- **Contradicts** the model complexity mismatch\n",
    "- **Linear model** cannot have low bias for cubic function\n",
    "- **Wrong assessment**\n",
    "\n",
    "**Option (b): Low bias, high variance**\n",
    "- **Linear model** cannot have low bias for cubic function\n",
    "- **Simple model** typically has low variance\n",
    "- **Incorrect combination**\n",
    "\n",
    "**Option (d): High bias, high variance**\n",
    "- **Linear model** has low variance due to simplicity\n",
    "- **Wrong variance assessment**\n",
    "- **Incorrect combination**\n",
    "\n",
    "**Key insight:** **Simple models** (linear) approximating **complex functions** (cubic) result in **high bias, low variance** due to systematic underfitting.\n",
    "\n",
    "---\n",
    "\n",
    "**Problem 5. One Answer**\n",
    "\n",
    "Adding more basis functions to a linear regression model always leads to better prediction accuracy on new, unseen data.\n",
    "\n",
    "*   (a) True\n",
    "*   (b) False\n",
    "\n",
    "**Correct answers:** (b)\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "**This question tests understanding of overfitting** and model complexity.\n",
    "\n",
    "**Why (b) is correct:**\n",
    "\n",
    "**Adding more basis functions doesn't always improve prediction accuracy:**\n",
    "\n",
    "**1. Overfitting mechanism:**\n",
    "- **More basis functions** = higher model complexity\n",
    "- **Model can fit** training data perfectly\n",
    "- **Poor generalization** to unseen data\n",
    "- **High variance** due to complexity\n",
    "\n",
    "**2. Bias-variance tradeoff:**\n",
    "- **Low bias:** Model can capture complex patterns\n",
    "- **High variance:** Sensitive to training data noise\n",
    "- **Optimal complexity** exists for best generalization\n",
    "- **Beyond optimal point:** Performance degrades\n",
    "\n",
    "**3. Mathematical intuition:**\n",
    "- **Training error:** Decreases with complexity\n",
    "- **Test error:** U-shaped curve (decreases then increases)\n",
    "- **Optimal point:** Minimum test error\n",
    "- **Overfitting region:** Test error increases\n",
    "\n",
    "**4. Why (a) is incorrect:**\n",
    "- **Ignores overfitting** phenomenon\n",
    "- **Assumes complexity** always helps\n",
    "- **Contradicts** empirical evidence\n",
    "- **Wrong assumption**\n",
    "\n",
    "**Key insight:** **Model complexity** has **diminishing returns** - beyond optimal complexity, **overfitting** causes **worse generalization**.\n",
    "\n",
    "---\n",
    "\n",
    "**Problem 6. One Answer**\n",
    "\n",
    "What datasets from the training/validation/test data split should you utilize during hyperparameter tuning?\n",
    "\n",
    "*   (a) Training Data\n",
    "*   (b) Training Data, Validation Data\n",
    "*   (c) Training Data, Validation Data, Test Data\n",
    "*   (d) Training Data, Test Data\n",
    "\n",
    "**Correct answers:** (b)\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "**This question tests understanding of data splitting** and hyperparameter tuning best practices.\n",
    "\n",
    "**Why (b) is correct:**\n",
    "\n",
    "**Training and validation data should be used for hyperparameter tuning:**\n",
    "\n",
    "**1. Purpose of each dataset:**\n",
    "- **Training data:** Learn model parameters\n",
    "- **Validation data:** Tune hyperparameters\n",
    "- **Test data:** Final evaluation only\n",
    "- **Never use test data** for tuning\n",
    "\n",
    "**2. Data leakage prevention:**\n",
    "- **Test data** must remain unseen during development\n",
    "- **Using test data** for tuning creates bias\n",
    "- **Overestimates** model performance\n",
    "- **Invalidates** final evaluation\n",
    "\n",
    "**3. Hyperparameter tuning process:**\n",
    "- **Train models** with different hyperparameters on training data\n",
    "- **Evaluate performance** on validation data\n",
    "- **Select best hyperparameters** based on validation performance\n",
    "- **Final evaluation** on test data (once only)\n",
    "\n",
    "**4. Why other options are incorrect:**\n",
    "\n",
    "**Option (a): Training data only**\n",
    "- **No validation** to assess hyperparameters\n",
    "- **Cannot compare** different configurations\n",
    "- **No way to select** best hyperparameters\n",
    "\n",
    "**Option (c): Including test data**\n",
    "- **Data leakage** - test data used for tuning\n",
    "- **Biased performance** estimates\n",
    "- **Invalidates** final evaluation\n",
    "\n",
    "**Option (d): Training and test data**\n",
    "- **Data leakage** - test data used for tuning\n",
    "- **Same problem** as option (c)\n",
    "- **Wrong practice**\n",
    "\n",
    "**Key insight:** **Test data** must remain **completely unseen** during model development to provide **unbiased final evaluation**.\n",
    "\n",
    "---\n",
    "\n",
    "**Problem 7. One Answer**\n",
    "\n",
    "Consider $u = \\begin{bmatrix} 2 \\\\ 1 \\\\ 3 \\end{bmatrix}$, $v = \\begin{bmatrix} -4 \\\\ 5 \\\\ 1 \\end{bmatrix}$, $w = \\begin{bmatrix} 1 \\\\ 1 \\\\ -1 \\end{bmatrix}$. Let $x \\in \\mathbb{R}^3$. Does there exist unique $a, b, c \\in \\mathbb{R}$ such that $a \\cdot u + b \\cdot v + c \\cdot w = x$?\n",
    "\n",
    "*   (a) Yes\n",
    "*   (b) No\n",
    "*   (c) Not enough information to determine\n",
    "\n",
    "**Correct answers:** (a)\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "**This question tests understanding of linear algebra** and vector space properties.\n",
    "\n",
    "**Why (a) is correct:**\n",
    "\n",
    "**Three linearly independent vectors in $\\mathbb{R}^3$ form a basis:**\n",
    "\n",
    "**1. Linear independence:**\n",
    "- **Vectors $u, v, w$** are linearly independent\n",
    "- **No non-trivial** linear combination equals zero\n",
    "- **Determinant** of matrix $[u \\ v \\ w]$ is non-zero\n",
    "- **Full rank** matrix\n",
    "\n",
    "**2. Basis properties:**\n",
    "- **Three independent vectors** in $\\mathbb{R}^3$ span the space\n",
    "- **Any vector $x \\in \\mathbb{R}^3$** can be written as linear combination\n",
    "- **Unique coefficients** $a, b, c$ exist\n",
    "- **One-to-one and onto** mapping\n",
    "\n",
    "**3. Mathematical verification:**\n",
    "- **Matrix form:** $[u \\ v \\ w] \\begin{bmatrix} a \\\\ b \\\\ c \\end{bmatrix} = x$\n",
    "- **Unique solution:** $\\begin{bmatrix} a \\\\ b \\\\ c \\end{bmatrix} = [u \\ v \\ w]^{-1} x$\n",
    "- **Inverse exists** because vectors are independent\n",
    "- **Unique coefficients** guaranteed\n",
    "\n",
    "**4. Why other options are incorrect:**\n",
    "\n",
    "**Option (b): No unique solution**\n",
    "- **Contradicts** linear independence\n",
    "- **Independent vectors** guarantee unique solution\n",
    "- **Wrong conclusion**\n",
    "\n",
    "**Option (c): Not enough information**\n",
    "- **We have sufficient** information (3 independent vectors in $\\mathbb{R}^3$)\n",
    "- **Linear algebra** provides clear answer\n",
    "- **Unnecessary uncertainty**\n",
    "\n",
    "**Key insight:** **Three linearly independent vectors** in **$\\mathbb{R}^3$** form a **basis**, ensuring **unique representation** of any vector.\n",
    "\n",
    "---\n",
    "\n",
    "**Problem 8.**\n",
    "\n",
    "Consider data matrix $X \\in \\mathbb{R}^{n \\times d}$, label vector $y \\in \\mathbb{R}^n$, and regularization parameter $\\lambda > 0$. Write the closed form solution for ridge regression.\n",
    "\n",
    "**Answer:** $(X^T X + \\lambda I)^{-1} X^T y$\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "**This question tests understanding of ridge regression** and its closed-form solution.\n",
    "\n",
    "**Why this is the correct answer:**\n",
    "\n",
    "**Ridge regression adds L2 regularization to linear regression:**\n",
    "\n",
    "**1. Ridge regression objective:**\n",
    "$\\min_w \\|Xw - y\\|_2^2 + \\lambda \\|w\\|_2^2$\n",
    "\n",
    "**2. Setting gradient to zero:**\n",
    "$\\nabla_w (\\|Xw - y\\|_2^2 + \\lambda \\|w\\|_2^2) = 0$\n",
    "\n",
    "**3. Computing gradients:**\n",
    "- **Loss term:** $\\nabla_w \\|Xw - y\\|_2^2 = 2X^T(Xw - y)$\n",
    "- **Regularization term:** $\\nabla_w \\lambda \\|w\\|_2^2 = 2\\lambda w$\n",
    "\n",
    "**4. Solving the equation:**\n",
    "$2X^T(Xw - y) + 2\\lambda w = 0$\n",
    "\n",
    "$X^T X w - X^T y + \\lambda w = 0$\n",
    "\n",
    "$(X^T X + \\lambda I) w = X^T y$\n",
    "\n",
    "**5. Closed-form solution:**\n",
    "$w = (X^T X + \\lambda I)^{-1} X^T y$\n",
    "\n",
    "**Key insight:** **Ridge regression** adds **$\\lambda I$** to **$X^T X$** to ensure **invertibility** and provide **regularization**.\n",
    "\n",
    "---\n",
    "\n",
    "**Problem 9. One Answer**\n",
    "\n",
    "Consider a dataset containing three observations for a simple linear regression problem, where $y$ is the dependent variable and $x$ is the independent variable. The dataset is given as follows:\n",
    "\n",
    "| x | y |\n",
    "|---|---|\n",
    "| 1 | 7 |\n",
    "| 2 | 8 |\n",
    "| 3 | 9 |\n",
    "\n",
    "Find the coefficient $\\beta_1$ of the linear regression (without bias) $y = \\beta_1 x$ using the least squares as loss.\n",
    "\n",
    "*   (a) $\\frac{46}{14}$\n",
    "*   (b) $\\frac{14}{46}$\n",
    "*   (c) $\\frac{50}{14}$\n",
    "*   (d) $\\frac{14}{50}$\n",
    "\n",
    "**Correct answers:** (c)\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "**This question tests understanding of linear regression** and least squares estimation.\n",
    "\n",
    "**Step-by-step calculation:**\n",
    "\n",
    "**1. Data matrix construction:**\n",
    "$X = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}$, $Y = \\begin{bmatrix} 7 \\\\ 8 \\\\ 9 \\end{bmatrix}$\n",
    "\n",
    "**2. Matrix calculations:**\n",
    "$X^T X = [1 \\ 2 \\ 3] \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix} = 1^2 + 2^2 + 3^2 = 1 + 4 + 9 = 14$\n",
    "\n",
    "$X^T Y = [1 \\ 2 \\ 3] \\begin{bmatrix} 7 \\\\ 8 \\\\ 9 \\end{bmatrix} = 1 \\times 7 + 2 \\times 8 + 3 \\times 9 = 7 + 16 + 27 = 50$\n",
    "\n",
    "**3. Normal equation solution:**\n",
    "$\\beta_1 = (X^T X)^{-1} (X^T Y) = \\frac{1}{14} \\times 50 = \\frac{50}{14}$\n",
    "\n",
    "**4. Verification:**\n",
    "- **Model:** $y = \\beta_1 x$\n",
    "- **Predictions:** $\\hat{y}_1 = \\frac{50}{14} \\times 1 = \\frac{50}{14}$\n",
    "- **Predictions:** $\\hat{y}_2 = \\frac{50}{14} \\times 2 = \\frac{100}{14}$\n",
    "- **Predictions:** $\\hat{y}_3 = \\frac{50}{14} \\times 3 = \\frac{150}{14}$\n",
    "\n",
    "**Key insight:** **Normal equations** provide **closed-form solution** for **least squares** linear regression without bias term.\n",
    "\n",
    "---\n",
    "\n",
    "**Problem 10. One Answer**\n",
    "\n",
    "We can find the solution for LASSO by setting the gradient of the loss to 0 and solving for weight parameter $w$.\n",
    "\n",
    "*   (a) True\n",
    "*   (b) False\n",
    "\n",
    "**Correct answers:** (b)\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "**This question tests understanding of LASSO regression** and optimization methods.\n",
    "\n",
    "**Why (b) is correct:**\n",
    "\n",
    "**LASSO has no closed-form solution due to L1 regularization:**\n",
    "\n",
    "**1. LASSO objective function:**\n",
    "$\\min_w \\|Xw - y\\|_2^2 + \\lambda \\|w\\|_1$\n",
    "\n",
    "**2. L1 penalty properties:**\n",
    "- **Non-differentiable** at $w_i = 0$\n",
    "- **Creates sparsity** by setting coefficients to exactly zero\n",
    "- **No analytical solution** possible\n",
    "- **Requires iterative** optimization\n",
    "\n",
    "**3. Why gradient-based methods fail:**\n",
    "- **Subgradient** exists but not unique\n",
    "- **Cannot set gradient** to zero directly\n",
    "- **Coordinate descent** or **proximal gradient** needed\n",
    "- **No closed-form** solution exists\n",
    "\n",
    "**4. Comparison with Ridge:**\n",
    "- **Ridge:** L2 penalty, differentiable everywhere\n",
    "- **Ridge:** Closed-form solution exists\n",
    "- **LASSO:** L1 penalty, non-differentiable at zero\n",
    "- **LASSO:** Requires iterative optimization\n",
    "\n",
    "**5. Why (a) is incorrect:**\n",
    "- **Assumes** LASSO has closed-form solution\n",
    "- **Ignores** non-differentiability of L1 penalty\n",
    "- **Contradicts** optimization theory\n",
    "- **Wrong assumption**\n",
    "\n",
    "**Key insight:** **L1 regularization** creates **non-differentiability** at zero, making **closed-form solutions** impossible for LASSO.\n",
    "\n",
    "---\n",
    "\n",
    "**Problem 11. One Answer**\n",
    "\n",
    "You are building a model to detect fraudulent transactions from a dataset of 100K samples. What would be the most effective way to split and utilize your data?\n",
    "\n",
    "*   (a) Randomly take an 80-20 data split. Use 80% of the data for training, and 20% for both validation and evaluation.\n",
    "*   (b) Use the first 80% of the data for training, the next 10% for validation, and the last 10% for evaluation.\n",
    "*   (c) Randomly make a 80-10-10 data split. Use 80% of the data for training, 10% for validation, and 10% for evaluation.\n",
    "*   (d) Select a random 80% of the data for training, use the remaining 20% for validation. Evaluate on the training set.\n",
    "\n",
    "**Correct answers:** (c)\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "**This question tests understanding of data splitting** best practices for machine learning.\n",
    "\n",
    "**Why (c) is correct:**\n",
    "\n",
    "**Random 80-10-10 split is the standard approach:**\n",
    "\n",
    "**1. Proper data splitting:**\n",
    "- **Training (80%):** Learn model parameters\n",
    "- **Validation (10%):** Tune hyperparameters\n",
    "- **Test (10%):** Final evaluation only\n",
    "- **Random sampling** ensures representative splits\n",
    "\n",
    "**2. Why other options are incorrect:**\n",
    "\n",
    "**Option (a): 80-20 split for training and validation/test**\n",
    "- **Validation and test** should be separate\n",
    "- **Cannot use same data** for both purposes\n",
    "- **Data leakage** between validation and test\n",
    "\n",
    "**Option (b): Sequential splitting**\n",
    "- **Data may have** temporal dependencies\n",
    "- **Non-random splits** can introduce bias\n",
    "- **Training on past,** testing on future creates bias\n",
    "- **Not representative** of real-world scenario\n",
    "\n",
    "**Option (d): Training and validation only**\n",
    "- **No test set** for final evaluation\n",
    "- **Cannot assess** true generalization\n",
    "- **Overfitting** to validation set possible\n",
    "- **No unbiased** performance estimate\n",
    "\n",
    "**3. Best practices:**\n",
    "- **Random sampling** ensures i.i.d. assumption\n",
    "- **Stratified sampling** for imbalanced datasets\n",
    "- **Sufficient data** in each split\n",
    "- **No overlap** between splits\n",
    "\n",
    "**Key insight:** **Random 80-10-10 split** provides **proper separation** of concerns and **unbiased evaluation**.\n",
    "\n",
    "---\n",
    "\n",
    "**Problem 12. One Answer**\n",
    "\n",
    "You are implementing a model to predict house prices. Your dataset contains 15 features (e.g., location, acres, proximity to city, etc.). However, you believe that many of these features are irrelevant to the house prices. Which method would be most suitable for your model?\n",
    "\n",
    "*   (a) Logistic regression with L1 regularization.\n",
    "*   (b) Logistic regression with L2 regularization.\n",
    "*   (c) Linear regression with L1 regularization.\n",
    "*   (d) Linear regression with L2 regularization.\n",
    "\n",
    "**Correct answers:** (c)\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "**This question tests understanding of model selection** and regularization for feature selection.\n",
    "\n",
    "**Why (c) is correct:**\n",
    "\n",
    "**Linear regression with L1 regularization is best for feature selection:**\n",
    "\n",
    "**1. Problem analysis:**\n",
    "- **Regression task:** Predicting house prices (continuous output)\n",
    "- **Feature selection needed:** Many irrelevant features\n",
    "- **15 features:** Need to identify important ones\n",
    "- **L1 regularization:** Creates sparsity\n",
    "\n",
    "**2. Why linear regression:**\n",
    "- **Continuous target:** House prices are continuous values\n",
    "- **Not classification:** No binary/multi-class labels\n",
    "- **Linear relationship:** Assumes linear feature relationships\n",
    "- **Interpretable:** Coefficients show feature importance\n",
    "\n",
    "**3. Why L1 regularization:**\n",
    "- **Feature selection:** Sets irrelevant coefficients to exactly zero\n",
    "- **Sparsity:** Creates sparse weight vector\n",
    "- **Interpretability:** Clear feature importance\n",
    "- **Automatic selection:** No manual feature elimination\n",
    "\n",
    "**4. Why other options are incorrect:**\n",
    "\n",
    "**Option (a): Logistic regression with L1**\n",
    "- **Wrong task:** Classification, not regression\n",
    "- **House prices** are continuous, not categorical\n",
    "- **Inappropriate** model choice\n",
    "\n",
    "**Option (b): Logistic regression with L2**\n",
    "- **Wrong task:** Classification, not regression\n",
    "- **L2 doesn't create** sparsity for feature selection\n",
    "- **Double wrong** choice\n",
    "\n",
    "**Option (d): Linear regression with L2**\n",
    "- **Correct task** but wrong regularization\n",
    "- **L2 shrinks** coefficients but doesn't set them to zero\n",
    "- **No feature selection** capability\n",
    "\n",
    "**Key insight:** **Linear regression with L1 regularization** provides **feature selection** for **regression tasks** with **many irrelevant features**.\n",
    "\n",
    "---\n",
    "\n",
    "**Problem 13. Select All That Apply**\n",
    "\n",
    "While training a model, you notice that it has a small bias but a high variance on the training data. Which of the following are valid strategies to address the high variance?\n",
    "\n",
    "*   (a) Increase regularization constant.\n",
    "*   (b) Train on a model class that is simpler.\n",
    "*   (c) Increase the size of the training dataset.\n",
    "*   (d) Use higher-degree features to capture more complex patterns in the data.\n",
    "\n",
    "**Correct answers:** (a), (b), (c)\n",
    "\n",
    "**Explanation:** A and B are correct because increasing regularization and simplifying model complexity help decrease the impact of less important features, improving generalization and reducing variance. C is also correct because increasing the training set size allows the model to generalize better, which can reduce variance. D is incorrect since using higher-degree features increases model complexity and often leads to overfitting, increasing variance.\n",
    "\n",
    "**Problem 14. Select All That Apply**\n",
    "\n",
    "After a student trains and evaluates a Logistic Regression model, you notice their test accuracy is 99.99%. You know that this was supposed to be a difficult dataset to model, so you investigate. Which of the following are reasonable explanations for this excessively high accuracy? Note that if you select multiple answers, not all of them have to be true at the same time.\n",
    "\n",
    "*   (a) There was some form of train/test leakage, resulting in the model over-performing on the test set\n",
    "*   (b) The data was not linearly separable, making it very easy for the model to classify things correctly\n",
    "*   (c) The dataset was incredibly imbalanced, with most of the data points being labeled as positives\n",
    "*   (d) The dataset was incredibly imbalanced, with most of the data points being labeled as negatives\n",
    "\n",
    "**Correct answers:** (a), (c), (d)\n",
    "\n",
    "**Explanation:** A is true. Train/test leakage can result in incredibly high performance on the evaluation data. C and D are also true. A very imbalanced dataset can make it so that the model only predicts the majority class yet scores very high. B is false as having data that is not linearly separable does not make it easier for a linear model to separate the classes.\n",
    "\n",
    "**Problem 15. One Answer**\n",
    "\n",
    "Given $W \\in \\mathbb{R}^{m \\times n}, X \\in \\mathbb{R}^{n \\times n}, Y \\in \\mathbb{R}^{p \\times m}, Z \\in \\mathbb{R}^{m \\times m}$, and $a \\in \\mathbb{R}^n$. If $m, n, p$ are distinct, which one of the following expressions is valid?\n",
    "\n",
    "*   (a) $(X^{-1}aa^T W^T)^{-1}(X^T a)$\n",
    "*   (b) $Xa^T aW^T (Z^{-1}Y^T)$\n",
    "*   (c) $WXaa^T XZY^T$\n",
    "*   (d) None of the above\n",
    "\n",
    "**Correct answers:** (b)\n",
    "\n",
    "**Explanation:** A is incorrect because $X^{-1}aa^T W^T \\in \\mathbb{R}^{n \\times m}$, and you cannot take the inverse of a non-square matrix. B is correct because even though $Xa^T$ is not possible ($n \\times n, 1 \\times n$), $a^T a$ becomes a scalar and allows for the expression to be valid. C is incorrect because $XZ$ is not possible ($n \\times n, m \\times m$). D is incorrect because B is correct.\n",
    "\n",
    "**Problem 16.**\n",
    "\n",
    "For what value of $k$ will $k$-fold cross-validation create cross-validation splits equivalent to Leave-one-out cross-validation (LOOCV)? Assume you have $n$ data points.\n",
    "\n",
    "**Answer:** $k = n$\n",
    "\n",
    "**Explanation:** If $k = n$, then there will be $n$ folds, each one only leaving 1 datapoint out. This is equivalent to LOOCV.\n",
    "\n",
    "**Problem 17. One Answer**\n",
    "\n",
    "We can decrease the variance of a model by increasing the model complexity.\n",
    "\n",
    "*   (a) True\n",
    "*   (b) False\n",
    "\n",
    "**Correct answers:** (b)\n",
    "\n",
    "**Explanation:** As model complexity increases, this increases the variance error due to higher degree of freedom.\n",
    "\n",
    "**Problem 18. Select All That Apply**\n",
    "\n",
    "Which of the following statements are true about logistic regression? Recall that the sigmoid function is defined as $\\sigma(x) = \\frac{1}{1+e^{-x}}$ for $x \\in \\mathbb{R}$\n",
    "\n",
    "*   (a) L2 regularization is often used to reduce overfitting in logistic regression by adding a penalty for large coefficient values\n",
    "*   (b) The logistic sigmoid function is used to model the probability of the positive class in binary logistic regression\n",
    "*   (c) The maximum likelihood estimates for the logistic regression coefficients can be found in closed-form\n",
    "*   (d) For any finite input $x \\in \\mathbb{R}$, $\\sigma(x)$ is strictly greater than 0 and strictly less than 1. Thus, a binary logistic regression model with finite input and weights can never output a probability of exactly 0 or 1, and can never achieve a training loss of exactly 0.\n",
    "\n",
    "**Correct answers:** (a), (b), (d)\n",
    "\n",
    "**Explanation:** The MLE for logistic regression coefficients cannot be found in closed-form which is why an iterative approach (eg. SGD) is used to find the coefficients.\n",
    "\n",
    "(d) True. $\\sigma(x)$ has horizontal asymptotes at 0 and 1 and therefore is strictly bounded between those values. Because the output probability is the output of, this implies that the output probability is also strictly contained in (0,1). As it cannot output positive or negative labels with probability 1, it is therefore unable to reduce the training loss to exactly 0, though it can get arbitrarily close.\n",
    "\n",
    "**Problem 19. Select All That Apply**\n",
    "\n",
    "Below are several statements about the train/test/validation sets and cross-validation. Which of the following are correct?\n",
    "\n",
    "*   (a) k-fold cross validation (where $k > 1$) is faster but more biased than leave-one-out (LOO) cross validation.\n",
    "*   (b) k-fold cross validation (where $k > 1$) is faster and more accurate than leave-one-out (LOO) cross validation.\n",
    "*   (c) The test set can be used to evaluate models during training and for hyperparameter tuning.\n",
    "*   (d) The test error gives us an assessment of how our model does on unseen data.\n",
    "\n",
    "**Correct answers:** (a), (d)\n",
    "\n",
    "**Explanation:** A is correct since k-fold is faster but generally more biased. D is correct since the purpose of the test set is to test the model on unseen data and assess its performance.\n",
    "\n",
    "**Problem 20. Select All That Apply**\n",
    "\n",
    "Consider the principle of Maximum Likelihood Estimation (MLE), which is a method to estimate the parameters of a statistical model. Which of the following statements is correct?\n",
    "\n",
    "*   (a) For MLE, samples must be drawn i.i.d. (independent and identically distributed).\n",
    "*   (b) Once we have a log-likelihood function, we maximize it with respect to the parameter $\\theta$ to find the parameter estimate $\\hat{\\theta}_{MLE}$.\n",
    "*   (c) MLE always provides an unbiased estimator of the true parameter.\n",
    "*   (d) MLE identifies the model parameters that maximize the likelihood of the observed data.\n",
    "\n",
    "**Correct answers:** (b), (d)\n",
    "\n",
    "**Explanation:** While i.i.d. is commonly assumed when doing MLE, it is not strictly necessary. Additionally, although it can sometimes be unbiased, MLE is generally a biased estimator.\n",
    "\n",
    "**Problem 21. One Answer**\n",
    "\n",
    "If we run gradient descent on $f(x)$, gradient descent guarantees that we will converge to the global minimum even if $\\nabla^2f(x) \\ge 0$ does not hold some $x$, i.e., the Hessian of the objective function is not positive semi-definite for some $x$.\n",
    "\n",
    "*   (a) True\n",
    "*   (b) False\n",
    "\n",
    "**Correct answers:** (b)\n",
    "\n",
    "**Explanation:** Gradient descent only guarantees a global minimum if $f(x)$ is convex.\n",
    "\n",
    "**Problem 22. One Answer**\n",
    "\n",
    "Let $A_1, A_2,..., A_n \\sim N(\\mu, \\sigma^2)$. What is $E[A_1 + A_2 + A_3]$?\n",
    "\n",
    "*   (a) $3\\mu$\n",
    "*   (b) $6\\mu$\n",
    "*   (c) $9\\mu$\n",
    "*   (d) Cannot be determined from the given information.\n",
    "\n",
    "**Correct answers:** (a)\n",
    "\n",
    "**Explanation:** By linearity of expectation, $E[A_1 + A_2 + A_3] = E[A_1] + E[A_2] + E[A_3]$. Since $A_1, A_2,..., A_n \\sim N(\\mu, \\sigma^2)$, $E[A_1] = E[A_2] = E[A_3] = \\mu$. Thus, $E[A_1] + E[A_2] + E[A_3] = \\mu + \\mu + \\mu = 3\\mu$.\n",
    "\n",
    "**Problem 23.**\n",
    "\n",
    "Consider a function $f(x,y)$ representing a loss function in a 2-dimensional space, where gradient descent is used to minimize $f$. Given the function: $f(x, y) = x^2 + 2y^2 + 4xy$ where the initial point is $(x_0, y_0) = (1, 1)$ and the learning rate is 0.1, write down the $(x_1, y_1)$ you get after one step of gradient descent.\n",
    "\n",
    "**Answer:** $(x_1, y_1) = (0.4, 0.2)$\n",
    "\n",
    "**Explanation:** From the gradient descent algorithm: $x_1 = x_0 - \\eta \\cdot \\frac{\\partial f(x_0, y_0)}{\\partial x}$ and $y_1 = y_0 - \\eta \\cdot \\frac{\\partial f(x_0, y_0)}{\\partial y}$. It is given that $\\eta = 0.1$. $\\frac{\\partial f(x,y)}{\\partial x} = 2x + 4y$. $\\frac{\\partial f(x,y)}{\\partial y} = 4y + 4x$. So, $x_1 = 1 - 0.1 \\cdot 6 = 0.4$ and $y_1 = 1 - 0.1 \\cdot 8 = 0.2$.\n",
    "\n",
    "**Problem 24. One Answer**\n",
    "\n",
    "For machine learning models and datasets in general, as the number of training data points grows, the prediction error of the model on unseen data (data not found in the training set) eventually reaches 0.\n",
    "\n",
    "*   (a) True\n",
    "*   (b) False\n",
    "\n",
    "**Correct answers:** (b)\n",
    "\n",
    "**Explanation:** There is irreducible error that leads to non-zero error.\n",
    "\n",
    "**Problem 25. One Answer**\n",
    "\n",
    "Which of the following statements about ridge regression are true?\n",
    "\n",
    "*   (a) When there are correlated features, ridge regression typically sets the weights of all but one of the correlated features to 0.\n",
    "*   (b) Compared to unregularized linear regression, the additional computational cost of ridge regression increases proportional to the number of data points in the dataset.\n",
    "*   (c) Ridge regression reduces variance at the expense of increasing bias.\n",
    "*   (d) Using ridge and lasso regularization together (e.g., minimizing a training objective of the form $f(w) = \\sum_{i=1}^n (y^{(i)} - x^{(i)T}w)^2 + \\lambda_1||w||_1 + \\lambda_2||w||_2^2$) makes the training loss no longer convex.\n",
    "\n",
    "**Correct answers:** (c)\n",
    "\n",
    "**Explanation:** Ridge regression typically shrinks the weights of correlated features about evenly. This means it probably won't set the weights of all but one of the correlated features to 0. That would be more akin to LASSO regression. The additional computational cost increases proportional to the number of weights in the dataset. Ridge-regression is an example of the bias-variance trade off. The sum of convex functions is convex so ridge and LASSO regression combined is still convex.\n",
    "\n",
    "**Problem 26. Select All That Apply**\n",
    "\n",
    "Let $n \\in \\mathbb{N}$ such that $n > 1$. Which of the following functions are convex (with respect to $x$) over its entire domain?\n",
    "\n",
    "*   (a) $f(x) = 5 + \\sum_{i=1}^{n} x^{2i}$\n",
    "*   (b) $f(x) = 5 + \\sum_{i=1}^{n} x^{2i+1}$\n",
    "*   (c) $f(x) = 3 \\cdot e^{-\\frac{x^2}{n}}$\n",
    "*   (d) $f(x) = x - \\log_{\\pi}(x^n)$ on $(0, \\infty)$\n",
    "\n",
    "**Correct answers:** (a), (d)\n",
    "\n",
    "**Explanation:** Below is an explanation for each option:\n",
    "\n",
    "**(a) Explanation:** Even (positive) monomials are convex, and a sum over convex functions is convex.\n",
    "\n",
    "**(b) Explanation:** Similarly, odd monomials are strictly concave on $(-\\infty, 0)$, so their sum will be strictly concave on $(-\\infty, 0)$.\n",
    "\n",
    "**(c) Explanation:** $3 \\cdot e^{-\\frac{x^2}{n}}$ is not convex (recall the shape of the Gaussian).\n",
    "\n",
    "**(d) Explanation:** $\\log x$ is concave, and $x$ is convex, so $x - \\log_{\\pi}(x^n) = x - n \\cdot \\log_{\\pi}(x)$ is convex on $(0, \\infty)$.\n",
    "\n",
    "**Problem 27.**\n",
    "\n",
    "Assume $n \\neq d$. Suppose $x_1, x_2, \\dots, x_n$ span $\\mathbb{R}^d$. What is the rank of $\\sum_{i=1}^{n} x_i x_i^T$? Write your answer in terms of $n$ and $d$. Hint: for any matrix $A$, $\\text{rank}(A^T A) = \\text{rank}(A)$.\n",
    "\n",
    "**Answer:** $d$\n",
    "\n",
    "**Explanation:** Let $X = \\begin{bmatrix} x_1^T \\\\ \\vdots \\\\ x_n^T \\end{bmatrix}$. Note that since $x_1, x_2, \\dots, x_n$ span $\\mathbb{R}^d$, $\\text{rank}(X) = d$. Also notice $X^T X = \\sum_{i=1}^{n} x_i x_i^T$. So\n",
    "\n",
    "$\\text{rank}\\left(\\sum_{i=1}^{n} x_i x_i^T\\right) = \\text{rank}(X^T X)$\n",
    "\n",
    "$= \\text{rank}(X)$\n",
    "\n",
    "$= d$\n",
    "\n",
    "**Takeaway:** The takeaway here is that our design matrix $X^T X$ is full rank (invertible) if and only if our data spans $\\mathbb{R}^d$.\n",
    "\n",
    "**Problem 28.**\n",
    "\n",
    "Describe one advantage of full-batch gradient descent over mini-batch gradient descent.\n",
    "\n",
    "**Answer:** Full batch gradient descent will be more accurate when calculating the gradient as it uses the whole dataset while mini-batch gradient descent uses a subset of the dataset to calculate gradient. This result in a more stable convergence.\n",
    "\n",
    "**Explanation:** Full batch gradient descent will be more accurate when calculating the gradient as it uses the whole dataset while mini-batch gradient descent uses a subset of the dataset to calculate gradient. This result in a more stable convergence.\n",
    "\n",
    "**Problem 29.**\n",
    "\n",
    "Describe one advantage of mini-batch stochastic gradient descent ($1 < B < n$) over stochastic gradient descent with batch size $B = 1$ (e.g., updating the parameters at each iteration based only on one randomly sampled training point).\n",
    "\n",
    "**Answer:** Mini-batch stochastic gradient descent will be more stable as it uses a subset of the training data for gradient calculation while stochastic gradient descent with batch-size 1 calculates gradient based on only one training data point making it more susceptible to noise.\n",
    "\n",
    "**Explanation:** Mini-batch stochastic gradient descent will be more stable as it uses a subset of the training data for gradient calculation while stochastic gradient descent with batch-size 1 calculates gradient based on only one training data point making it more susceptible to noise.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
